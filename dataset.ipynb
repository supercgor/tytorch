{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydoc import visiblename\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10\n",
    "# 讀取訓練集\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    \"./data/CIFAR-10/\", train=True, transform=None, target_transform=None, download=False)\n",
    "\n",
    "# 讀取測試集\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    \"./data/CIFAR-10/\", train=False, transform=None, target_transform=None, download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義數據強化模式\n",
    "custom_transform = transforms.transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定義新訓練集\n",
    "enhenced_train_data = torchvision.datasets.CIFAR10(\n",
    "    \"./data/CIFAR-10/\", train=True, transform=custom_transform, target_transform=None, download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量讀取數據\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=2, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist unpack\n",
    "import os\n",
    "from skimage import io\n",
    "import torchvision.datasets.mnist as mnist\n",
    "\n",
    "# 數據解碼\n",
    "root = r\"./data/MNIST/raw/\"\n",
    "\n",
    "train_set = (\n",
    "    mnist.read_image_file(os.path.join(root,\"train-images-idx3-ubyte\")),\n",
    "    mnist.read_label_file(os.path.join(root, 'train-labels-idx1-ubyte'))\n",
    ")\n",
    "\n",
    "test_set = (\n",
    "    mnist.read_image_file(os.path.join(root, 't10k-images-idx3-ubyte')),\n",
    "    mnist.read_label_file(os.path.join(root, 't10k-labels-idx1-ubyte'))\n",
    ")\n",
    "\n",
    "# 數據量展示\n",
    "print(f\"train set: {train_set[0].size()}\")\n",
    "print(f\"test set : {test_set[0].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_img(save_path, train=True):\n",
    "    '''\n",
    "    将图片存储在本地，并制作索引文件\n",
    "    @para: save_path  图像保存路径，将在路径下创建train、test文件夹分别存储训练集和测试集\n",
    "    @para: train      默认True，本地存储训练集图像，否则本地存储测试集图像 \n",
    "    '''\n",
    "    if train:\n",
    "        f = open(save_path + \"train.txt\", 'w')\n",
    "        data_path = save_path + '/train/'\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path)\n",
    "        for i, (img, label) in enumerate(zip(train_set[0], train_set[1])):\n",
    "            img_path = data_path + str(i) + '.jpg'\n",
    "            io.imsave(img_path,img.numpy())\n",
    "            int_label = str(label).replace(\"tensor(\",\"\").replace(\")\",\"\")\n",
    "            f.write(f\"{i}.jpg,{int_label}\\n\")\n",
    "        f.close()\n",
    "    else:\n",
    "        f = open(save_path + \"test.txt\",\"w\")\n",
    "        data_path = f\"{save_path}/test/\"\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path)\n",
    "        for i, (img,label) in enumerate(zip(test_set[0],test_set[1])):\n",
    "            img_path = f\"{data_path}{i}.jpg\"\n",
    "            io.imsave(img_path,img.numpy())\n",
    "            int_label = str(label).replace(\"tensor(\",\"\").replace(\")\",\"\")\n",
    "            f.write(f\"{i}.jpg,{int_label}\\n\")\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換數據集\n",
    "save_path = r\"./data/MNIST/processed/\"\n",
    "#convert_to_img(save_path, True)\n",
    "#convert_to_img(save_path, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):  # 繼承Dataset類\n",
    "    def __init__(self, image_path, image_label, transform=None):\n",
    "        # 初始化圖像文件路徑或圖像文件名列表等\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.image_path = image_path\n",
    "        self.image_label = image_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1.根据索引index从文件中读取一个数据（例如，使用numpy.fromfile，PIL.Image.open，cv2.imread）\n",
    "        # 2.预处理数据（例如torchvision.Transform）\n",
    "        # 3.返回数据对（例如图像和标签）\n",
    "        image = Image.open(self.image_path[index])\n",
    "        image = np.array(image)\n",
    "        label = float(self.image_label[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "def get_path_label(img_root, label_file_path):\n",
    "    \"\"\"\n",
    "    获取数字图像的路径和标签并返回对应列表\n",
    "    @para: img_root: 保存图像的根目录\n",
    "    @para:label_file_path: 保存图像标签数据的文件路径 .csv 或 .txt 分隔符为','\n",
    "    @return: 图像的路径列表和对应标签列表\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(label_file_path, names=[\"img\",\"label\"])\n",
    "    data['img'] = data['img'].apply(lambda x: img_root + x)\n",
    "    \n",
    "    return data['img'].tolist(), data['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲取訓練集路徑列表和標簽列表\n",
    "train_data_root = \"./data/MNIST/processed/train/\"\n",
    "train_label = \"./data/MNIST/processed/train.txt\"\n",
    "train_img_list, train_label_list = get_path_label(train_data_root, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練集dataset\n",
    "train_dataset = TestDataset(train_img_list, train_label_list,\n",
    "                            transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# 取得測試路徑列表和標簽列表\n",
    "test_data_root = \"./data/MNIST/processed/test/\"\n",
    "test_label = \"./data/MNIST/processed/test.txt\"\n",
    "test_img_list, test_label_list = get_path_label(test_data_root, test_label)\n",
    "\n",
    "# 測試集dataset\n",
    "test_dataset = TestDataset(test_img_list, test_label_list,\n",
    "                           transform=transforms.Compose([transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 訓練數據加載\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=3,\n",
    "    shuffle=True,\n",
    "    num_workers = 4\n",
    "    )\n",
    "\n",
    "# 測試數據加載\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=3,\n",
    "                        shuffle=False,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img_data in enumerate(train_loader, 1):\n",
    "    images, labels = img_data\n",
    "    print(f\"batch{i}:images shape info-->{images.shape},label-->{labels}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b54fb8822f8bd57b64387997ebc5890a6df68cdeb31085e8585fa83fd840068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
